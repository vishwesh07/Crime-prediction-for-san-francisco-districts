{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA TAKEN ON 5/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.sfgov.org\", None)\n",
    "# results = client.get(\"cuks-n6tp\", limit = 2191368)\n",
    "data = client.get(\"cuks-n6tp\", limit = 3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame.from_records(data)#here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2206399, 13)\n"
     ]
    }
   ],
   "source": [
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'address', u'category', u'date', u'dayofweek', u'descript',\n",
       "       u'incidntnum', u'location', u'pddistrict', u'pdid', u'resolution',\n",
       "       u'time', u'x', u'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('CITY_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'address' u'category' u'date' u'dayofweek' u'descript' u'incidntnum'\n",
      " u'location' u'pddistrict' u'pdid' u'resolution' u'time' u'x' u'y']\n"
     ]
    }
   ],
   "source": [
    "print(data_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'SOUTHERN', u'NORTHERN', u'RICHMOND', u'PARK', u'MISSION', u'BAYVIEW', u'INGLESIDE', u'TARAVAL', u'TENDERLOIN', u'CENTRAL', nan]\n"
     ]
    }
   ],
   "source": [
    "districts = data_df['pddistrict'].unique().tolist()\n",
    "print(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_df['pddistrict'] == 'BAYVIEW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BAYVIEW = data_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219461, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_BAYVIEW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BAYVIEW.to_csv('BAYVIEW_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it was exported properly by importing and checking shape/columns for only bayview\n",
    "df_bayview_check = pd.read_csv('BAYVIEW_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219461, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_bayview_check.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'address' u'category' u'date' u'dayofweek' u'descript' u'incidntnum'\n",
      " u'location' u'pddistrict' u'pdid' u'resolution' u'time' u'x' u'y']\n"
     ]
    }
   ],
   "source": [
    "print(df_BAYVIEW.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address' 'category' 'date' 'dayofweek' 'descript' 'incidntnum'\n",
      " 'location' 'pddistrict' 'pdid' 'resolution' 'time' 'x' 'y']\n"
     ]
    }
   ],
   "source": [
    "print(df_bayview_check.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'RICHMOND'\n",
    "df_RICHMOND = data_df[mask]\n",
    "df_RICHMOND.to_csv('RICHMOND_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115878, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_RICHMOND.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data_df['pddistrict'] == 'MISSION'\n",
    "df_MISSION = data_df[mask]\n",
    "df_MISSION.to_csv('MISSION_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'CENTRAL'\n",
    "df_CENTRAL = data_df[mask]\n",
    "df_CENTRAL.to_csv('CENTRAL_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'TARAVAL'\n",
    "df_TARAVAL = data_df[mask]\n",
    "df_TARAVAL.to_csv('TARAVAL_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'NORTHERN'\n",
    "df_NORTHERN = data_df[mask]\n",
    "df_NORTHERN.to_csv('NORTHERN_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'SOUTHERN'\n",
    "df_SOUTHERN = data_df[mask]\n",
    "df_SOUTHERN.to_csv('SOUTHERN_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'PARK'\n",
    "df_PARK = data_df[mask]\n",
    "df_PARK.to_csv('PARK_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'INGLESIDE'\n",
    "df_INGLESIDE = data_df[mask]\n",
    "df_INGLESIDE.to_csv('INGLESIDE_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse this for all csvs, only doing bayview for now...\n",
    "mask = data_df['pddistrict'] == 'TENDERLOIN'\n",
    "df_TENDERLOIN = data_df[mask]\n",
    "df_TENDERLOIN.to_csv('TENDERLOIN_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = pd.read_csv('BAYVIEW_data.csv') #change this city for csv for whatever district being done\n",
    "df_district = df_district.drop(columns=['pddistrict', 'incidntnum', 'pdid', 'location', 'descript'])\n",
    "df_y = df_bayview['category']\n",
    "df_x = df_district.drop(columns=['category'])\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder = labelencoder.fit(df_y)\n",
    "labelencoded_y = labelencoder.transform(df_y)\n",
    "df_x['day'] = df_x.date.apply(lambda x: convert_date_to_day(x))\n",
    "df_x['month'] = df_x.date.apply(lambda x: convert_date_to_month(x))\n",
    "df_x['year'] = df_x.date.apply(lambda x: convert_date_to_year(x))\n",
    "df_x['hour'] = df_x.time.apply(lambda x: convert_time_to_hour(x))\n",
    "df_x = df_x.drop(columns=['date', 'time'])\n",
    "df_x['day'] = (df_x['day']).astype(int)\n",
    "df_x['month'] = (df_x['month']).astype(int)\n",
    "df_x['year'] = (df_x['year']).astype(int)\n",
    "df_x['hour'] = (df_x['hour']).astype(int)\n",
    "label_encoder_addr = LabelEncoder()\n",
    "addr_feature = label_encoder_addr.fit_transform(df_x_int.address.iloc[:].values)\n",
    "addr_feature = addr_feature.reshape(df_x_int.shape[0], 1)\n",
    "onehot_encoder_addr = OneHotEncoder(sparse = False)\n",
    "addr_feature = onehot_encoder_addr.fit_transform(addr_feature)\n",
    "label_encoder_DoW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DoW.fit_transform(df_x_int.dayofweek.iloc[:].values)\n",
    "DoW_feature = DoW_feature.reshape(df_x_int.shape[0], 1)\n",
    "onehot_encoder_DoW = OneHotEncoder(sparse = False)\n",
    "DoW_feature = onehot_encoder_DoW.fit_transform(DoW_feature)\n",
    "label_encoder_res = LabelEncoder()\n",
    "res_feature = label_encoder_res.fit_transform(df_x_int.resolution.iloc[:].values)\n",
    "res_feature = res_feature.reshape(df_x_int.shape[0], 1)\n",
    "onehot_encoder_res = OneHotEncoder(sparse = False)\n",
    "res_feature = onehot_encoder_res.fit_transform(res_feature)\n",
    "\n",
    "day = df_x.day.values\n",
    "month = df_x.month.values\n",
    "year = df_x.year.values\n",
    "hour = df_x.hour.values\n",
    "x = df_x.x.values\n",
    "y = df_x.y.values\n",
    "\n",
    "columns = []\n",
    "columns.append(addr_feature)\n",
    "columns.append(DoW_feature)\n",
    "columns.append(res_feature)\n",
    "columns.append(x)\n",
    "columns.append(y)\n",
    "columns.append(day)\n",
    "columns.append(month)\n",
    "columns.append(year)\n",
    "columns.append(hour)\n",
    "encoded_feats = column_stack(columns)\n",
    "sparse_features = sparse.csr_matrix(encoded_feats)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sparse_features, labelencoded_y, test_size=0.20, random_state=random_seed)\n",
    "\n",
    "model = XGBClassifier(nthread = n_threads) #or -1\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "param_grid = {'n_estimators': stats.randint(100,500), #random int btwn 100 and 500\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.4) #btwn .1 and 1.0    \n",
    "}\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'f1_micro', n_iter = 5, n_jobs=-1, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_parameters = rand_result.best_estimator_\n",
    "#INSERT CITY NAME FOR .DAT FILE\n",
    "pickle.dump(best_XGB_LE_estimator, open(\"xgb_CITYHERE.pickle.dat, \"wb\"\"))\n",
    "#test on test set\n",
    "best_XGB_parameters.fit(X_train, y_train)\n",
    "#CSV append best score after test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
